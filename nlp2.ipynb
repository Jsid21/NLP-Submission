{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWg_EbLrwhHf",
        "outputId": "51eb5971-bc57-47db-b872-d8771cd32e3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "documents = [\"I love programming\", \"Programming is fun\", \"I love coding\"]\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the documents to create the Bag-of-Words model\n",
        "X = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Convert to an array for easy reading\n",
        "word_counts = X.toarray()\n",
        "\n",
        "# Normalize word counts by the total words in the document\n",
        "normalized_counts = word_counts / word_counts.sum(axis=1, keepdims=True)\n",
        "\n",
        "# Get feature names (words)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Display results\n",
        "print(\"Words:\", feature_names)\n",
        "print(\"Word Counts:\", word_counts)\n",
        "print(\"Normalized Counts:\", normalized_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc-NwfIa0PUi",
        "outputId": "52170ee9-ee6b-4e71-834f-73ef1aec28bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words: ['coding' 'fun' 'is' 'love' 'programming']\n",
            "Word Counts: [[0 0 0 1 1]\n",
            " [0 1 1 0 1]\n",
            " [1 0 0 1 0]]\n",
            "Normalized Counts: [[0.         0.         0.         0.5        0.5       ]\n",
            " [0.         0.33333333 0.33333333 0.         0.33333333]\n",
            " [0.5        0.         0.         0.5        0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Sample data\n",
        "documents = [\"I love programming\", \"Programming is fun\", \"I love coding\"]\n",
        "\n",
        "# Initialize TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the documents to create the TF-IDF model\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "# Convert to array for easy reading\n",
        "tfidf_array = tfidf_matrix.toarray()\n",
        "\n",
        "# Get feature names (words)\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Display results\n",
        "print(\"Words:\", feature_names)\n",
        "print(\"TF-IDF Scores:\", tfidf_array)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0FgA1gb0j-w",
        "outputId": "2100ebbd-cdec-4ef7-9aea-1d1c70502a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words: ['coding' 'fun' 'is' 'love' 'programming']\n",
            "TF-IDF Scores: [[0.         0.         0.         0.70710678 0.70710678]\n",
            " [0.         0.62276601 0.62276601 0.         0.4736296 ]\n",
            " [0.79596054 0.         0.         0.60534851 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Sample data\n",
        "documents = [\"I love programming\", \"Programming is fun\", \"I love coding\"]\n",
        "\n",
        "# Tokenize the sentences into words (this step may involve more sophisticated preprocessing)\n",
        "tokenized_documents = [doc.split() for doc in documents]\n",
        "\n",
        "# Initialize and train the Word2Vec model\n",
        "model = Word2Vec(tokenized_documents, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Get word embeddings (vectors) for each word in the vocabulary\n",
        "embeddings = {word: model.wv[word] for word in model.wv.index_to_key}\n",
        "\n",
        "# Display word embeddings for a specific word\n",
        "print(\"Embedding for 'programming':\", embeddings['programming'])\n"
      ],
      "metadata": {
        "id": "3hNalMsj0pF5",
        "outputId": "b1668d79-1cf3-4c44-ed8a-8cd6c8b4ab4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding for 'programming': [ 8.13227147e-03 -4.45733406e-03 -1.06835726e-03  1.00636482e-03\n",
            " -1.91113955e-04  1.14817743e-03  6.11386076e-03 -2.02715401e-05\n",
            " -3.24596534e-03 -1.51072862e-03  5.89729892e-03  1.51410222e-03\n",
            " -7.24261976e-04  9.33324732e-03 -4.92128357e-03 -8.38409644e-04\n",
            "  9.17541143e-03  6.74942741e-03  1.50285603e-03 -8.88256077e-03\n",
            "  1.14874600e-03 -2.28825561e-03  9.36823711e-03  1.20992784e-03\n",
            "  1.49006362e-03  2.40640994e-03 -1.83600665e-03 -4.99963388e-03\n",
            "  2.32429506e-04 -2.01418041e-03  6.60093315e-03  8.94012302e-03\n",
            " -6.74754381e-04  2.97701475e-03 -6.10765442e-03  1.69932481e-03\n",
            " -6.92623248e-03 -8.69402662e-03 -5.90020278e-03 -8.95647518e-03\n",
            "  7.27759488e-03 -5.77203138e-03  8.27635173e-03 -7.24354526e-03\n",
            "  3.42167495e-03  9.67499893e-03 -7.78544787e-03 -9.94505733e-03\n",
            " -4.32914635e-03 -2.68313056e-03 -2.71289347e-04 -8.83155130e-03\n",
            " -8.61755759e-03  2.80021061e-03 -8.20640661e-03 -9.06933658e-03\n",
            " -2.34046578e-03 -8.63180775e-03 -7.05664977e-03 -8.40115082e-03\n",
            " -3.01328895e-04 -4.56429832e-03  6.62717456e-03  1.52716041e-03\n",
            " -3.34147573e-03  6.10897178e-03 -6.01328490e-03 -4.65616956e-03\n",
            " -7.20750913e-03 -4.33658017e-03 -1.80932996e-03  6.48964290e-03\n",
            " -2.77039292e-03  4.91896737e-03  6.90444233e-03 -7.46370573e-03\n",
            "  4.56485013e-03  6.12697843e-03 -2.95447465e-03  6.62502181e-03\n",
            "  6.12587947e-03 -6.44348515e-03 -6.76455162e-03  2.53895880e-03\n",
            " -1.62381888e-03 -6.06512791e-03  9.49920900e-03 -5.13014663e-03\n",
            " -6.55409694e-03 -1.19885204e-04 -2.70142802e-03  4.44400299e-04\n",
            " -3.53745813e-03 -4.19330609e-04 -7.08615757e-04  8.22820642e-04\n",
            "  8.19481723e-03 -5.73670724e-03 -1.65952800e-03  5.57160750e-03]\n"
          ]
        }
      ]
    }
  ]
}